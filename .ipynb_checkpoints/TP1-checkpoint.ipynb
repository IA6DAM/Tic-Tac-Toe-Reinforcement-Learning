{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74615a8-09d2-4ddf-b6cc-3d389b1f1bb0",
   "metadata": {},
   "source": [
    "<h1><center> LAB:1 Dynamic Programming For Tic-Tac-Toe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3f8753-fe65-45e8-b7d3-52fba27bb334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [' '] * 9  # 3x3 board represented as a list\n",
    "        self.current_winner = None  # Keep track of the winner!\n",
    "\n",
    "    def print_board(self):\n",
    "        # 3x3 tic-tac-toe board\n",
    "        for row in [self.board[i*3:(i+1)*3] for i in range(3)]:\n",
    "            print('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "    def available_moves(self):\n",
    "        return [i for i, spot in enumerate(self.board) if spot == ' ']\n",
    "\n",
    "    def empty_squares(self):\n",
    "        return ' ' in self.board\n",
    "\n",
    "    def num_empty_squares(self):\n",
    "        return self.board.count(' ')\n",
    "\n",
    "    def make_move(self, square, letter):\n",
    "        if self.board[square] == ' ':\n",
    "            self.board[square] = letter\n",
    "            if self.winner(square, letter):\n",
    "                self.current_winner = letter\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def winner(self, square, letter):\n",
    "        # Check rows, columns, and diagonals for a win\n",
    "        row_ind = square // 3\n",
    "        row = self.board[row_ind*3:(row_ind+1)*3]\n",
    "        if all([spot == letter for spot in row]):\n",
    "            return True\n",
    "        col_ind = square % 3\n",
    "        column = [self.board[col_ind+i*3] for i in range(3)]\n",
    "        if all([spot == letter for spot in column]):\n",
    "            return True\n",
    "        # Check diagonals\n",
    "        if square % 2 == 0:\n",
    "            diagonal1 = [self.board[i] for i in [0, 4, 8]]\n",
    "            if all([spot == letter for spot in diagonal1]):\n",
    "                return True\n",
    "            diagonal2 = [self.board[i] for i in [2, 4, 6]]\n",
    "            if all([spot == letter for spot in diagonal2]):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [' '] * 9\n",
    "        self.current_winner = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9bf708-05cc-4235-b663-0d9ecd6e75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomAgent:\n",
    "    def __init__(self, letter):\n",
    "        self.letter = letter  # X or O\n",
    "\n",
    "    def get_move(self, game):\n",
    "        available_moves = game.available_moves()\n",
    "        return random.choice(available_moves)  # Choose a random move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6adab971-8d70-4615-bd9c-aaf350cf817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktrackingAgent:\n",
    "    def __init__(self, letter):\n",
    "        self.letter = letter  # X or O\n",
    "\n",
    "    def get_move(self, game):\n",
    "        if len(game.available_moves()) == 9:\n",
    "            return random.choice(game.available_moves())  # Random move if it's the first move\n",
    "        else:\n",
    "            return self.minimax(game, self.letter)['position']\n",
    "\n",
    "    def minimax(self, state, player):\n",
    "        max_player = self.letter  # The player playing as this agent\n",
    "        other_player = 'O' if player == 'X' else 'X'\n",
    "\n",
    "        # Base case: check for winner\n",
    "        if state.current_winner == other_player:\n",
    "            return {'position': None, 'score': 1 * (state.num_empty_squares() + 1) if other_player == max_player else -1 * (state.num_empty_squares() + 1)}\n",
    "        elif not state.empty_squares():\n",
    "            return {'position': None, 'score': 0}\n",
    "\n",
    "        # Initialize move list\n",
    "        if player == max_player:\n",
    "            best = {'position': None, 'score': -float('inf')}\n",
    "        else:\n",
    "            best = {'position': None, 'score': float('inf')}\n",
    "\n",
    "        for possible_move in state.available_moves():\n",
    "            state.make_move(possible_move, player)\n",
    "            sim_score = self.minimax(state, other_player)  # Recurse\n",
    "\n",
    "            state.board[possible_move] = ' '  # Undo the move\n",
    "            state.current_winner = None  # Reset winner\n",
    "            sim_score['position'] = possible_move  # Update move\n",
    "\n",
    "            if player == max_player:  # Maximize the score\n",
    "                if sim_score['score'] > best['score']:\n",
    "                    best = sim_score\n",
    "            else:  # Minimize the score\n",
    "                if sim_score['score'] < best['score']:\n",
    "                    best = sim_score\n",
    "\n",
    "        return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6733359f-53bd-4edc-9d87-229e53db9400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Policy Agent Playing Alone:\n",
      "X makes a move to square 7\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "|   | X |   |\n",
      "O makes a move to square 3\n",
      "|   |   |   |\n",
      "| O |   |   |\n",
      "|   | X |   |\n",
      "X makes a move to square 2\n",
      "|   |   | X |\n",
      "| O |   |   |\n",
      "|   | X |   |\n",
      "O makes a move to square 4\n",
      "|   |   | X |\n",
      "| O | O |   |\n",
      "|   | X |   |\n",
      "X makes a move to square 6\n",
      "|   |   | X |\n",
      "| O | O |   |\n",
      "| X | X |   |\n",
      "O makes a move to square 5\n",
      "|   |   | X |\n",
      "| O | O | O |\n",
      "| X | X |   |\n",
      "O wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def play_game_random_agent():\n",
    "    game = TicTacToe()\n",
    "    random_agent_x = RandomAgent('X')\n",
    "    random_agent_o = RandomAgent('O')\n",
    "\n",
    "    letter = 'X'  # X starts first\n",
    "    while game.empty_squares():\n",
    "        if letter == 'X':\n",
    "            move = random_agent_x.get_move(game)\n",
    "        else:\n",
    "            move = random_agent_o.get_move(game)\n",
    "\n",
    "        if game.make_move(move, letter):\n",
    "            print(f'{letter} makes a move to square {move}')\n",
    "            game.print_board()\n",
    "\n",
    "            if game.current_winner:\n",
    "                print(f'{letter} wins!')\n",
    "                return letter  # Return the winner\n",
    "            letter = 'O' if letter == 'X' else 'X'  # Switch player\n",
    "\n",
    "    print('It\\'s a tie!')\n",
    "\n",
    "print(\"Random Policy Agent Playing Alone:\")\n",
    "play_game_random_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bf399fa-aade-4905-b6ee-ce531b468b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtracking Agent Playing Alone:\n",
      "X makes a move to square 4\n",
      "|   |   |   |\n",
      "|   | X |   |\n",
      "|   |   |   |\n",
      "O makes a move to square 0\n",
      "| O |   |   |\n",
      "|   | X |   |\n",
      "|   |   |   |\n",
      "X makes a move to square 1\n",
      "| O | X |   |\n",
      "|   | X |   |\n",
      "|   |   |   |\n",
      "O makes a move to square 7\n",
      "| O | X |   |\n",
      "|   | X |   |\n",
      "|   | O |   |\n",
      "X makes a move to square 3\n",
      "| O | X |   |\n",
      "| X | X |   |\n",
      "|   | O |   |\n",
      "O makes a move to square 5\n",
      "| O | X |   |\n",
      "| X | X | O |\n",
      "|   | O |   |\n",
      "X makes a move to square 2\n",
      "| O | X | X |\n",
      "| X | X | O |\n",
      "|   | O |   |\n",
      "O makes a move to square 6\n",
      "| O | X | X |\n",
      "| X | X | O |\n",
      "| O | O |   |\n",
      "X makes a move to square 8\n",
      "| O | X | X |\n",
      "| X | X | O |\n",
      "| O | O | X |\n",
      "It's a tie!\n"
     ]
    }
   ],
   "source": [
    "def play_game_backtracking_agent():\n",
    "    game = TicTacToe()\n",
    "    backtracking_agent_x = BacktrackingAgent('X')\n",
    "    backtracking_agent_o = BacktrackingAgent('O')\n",
    "\n",
    "    letter = 'X'  # X starts first\n",
    "    while game.empty_squares():\n",
    "        if letter == 'X':\n",
    "            move = backtracking_agent_x.get_move(game)\n",
    "        else:\n",
    "            move = backtracking_agent_o.get_move(game)\n",
    "\n",
    "        if game.make_move(move, letter):\n",
    "            print(f'{letter} makes a move to square {move}')\n",
    "            game.print_board()\n",
    "\n",
    "            if game.current_winner:\n",
    "                print(f'{letter} wins!')\n",
    "                return letter  # Return the winner\n",
    "            letter = 'O' if letter == 'X' else 'X'  # Switch player\n",
    "\n",
    "    print('It\\'s a tie!')\n",
    "\n",
    "print(\"Backtracking Agent Playing Alone:\")\n",
    "play_game_backtracking_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1acb55b-4c7d-433c-9495-2b2853866ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [' '] * 9  # 3x3 board represented as a list\n",
    "        self.current_winner = None  # Keep track of the winner!\n",
    "\n",
    "    def available_moves(self):\n",
    "        return [i for i, spot in enumerate(self.board) if spot == ' ']\n",
    "\n",
    "    def empty_squares(self):\n",
    "        return ' ' in self.board\n",
    "\n",
    "    def make_move(self, square, letter):\n",
    "        if self.board[square] == ' ':\n",
    "            self.board[square] = letter\n",
    "            if self.winner(square, letter):\n",
    "                self.current_winner = letter\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def winner(self, square, letter):\n",
    "        # Check rows, columns, and diagonals for a win\n",
    "        row_ind = square // 3\n",
    "        row = self.board[row_ind*3:(row_ind+1)*3]\n",
    "        if all([spot == letter for spot in row]):\n",
    "            return True\n",
    "        col_ind = square % 3\n",
    "        column = [self.board[col_ind+i*3] for i in range(3)]\n",
    "        if all([spot == letter for spot in column]):\n",
    "            return True\n",
    "        if square % 2 == 0:\n",
    "            diagonal1 = [self.board[i] for i in [0, 4, 8]]\n",
    "            if all([spot == letter for spot in diagonal1]):\n",
    "                return True\n",
    "            diagonal2 = [self.board[i] for i in [2, 4, 6]]\n",
    "            if all([spot == letter for spot in diagonal2]):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [' '] * 9\n",
    "        self.current_winner = None\n",
    "\n",
    "    def is_terminal(self):\n",
    "        if self.current_winner:\n",
    "            return True\n",
    "        if not self.empty_squares():\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee54f1b1-cecd-4b43-9b1a-932a4f545cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIterationAgent:\n",
    "    def __init__(self):\n",
    "        self.states = []  # List to store all board states\n",
    "        self.policy = {}  # Mapping from state to action\n",
    "        self.value_function = {}  # Mapping from state to value\n",
    "        self.gamma = 0.9  # Discount factor for future rewards\n",
    "        self.learning_rate = 0.1  # Learning rate for value updates\n",
    "\n",
    "    def initialize(self, game):\n",
    "        # Initialize the policy and value function for all states\n",
    "        for state in self.generate_all_states(game):\n",
    "            self.states.append(state)\n",
    "            self.policy[state] = random.choice(range(9))  # Random initial action\n",
    "            self.value_function[state] = 0  # Value function starts at 0\n",
    "\n",
    "    def generate_all_states(self, game):\n",
    "        # Generate all possible states (board configurations)\n",
    "        return [tuple(game.board)]  # Simplified: generate from an empty board\n",
    "\n",
    "    def choose_action(self, state, available_actions):\n",
    "        # Choose the action based on the current policy\n",
    "        if state in self.policy:\n",
    "            return self.policy[state]\n",
    "        else:\n",
    "            return random.choice(available_actions)  # Random fallback\n",
    "\n",
    "    def evaluate_policy(self, game):\n",
    "        # Policy Evaluation Step: Update the value function\n",
    "        for state in self.states:\n",
    "            game.board = list(state)\n",
    "            if game.is_terminal():\n",
    "                self.value_function[state] = self.reward(game)\n",
    "            else:\n",
    "                next_state = self.get_next_state(game, self.policy[state])\n",
    "                reward = self.reward(game)\n",
    "                self.value_function[state] = reward + self.gamma * self.value_function.get(next_state, 0)\n",
    "\n",
    "    def improve_policy(self, game):\n",
    "        # Policy Improvement Step: Update the policy based on value function\n",
    "        for state in self.states:\n",
    "            game.board = list(state)\n",
    "            available_actions = game.available_moves()\n",
    "            best_action = None\n",
    "            best_value = -float('inf')\n",
    "            for action in available_actions:\n",
    "                next_state = self.get_next_state(game, action)\n",
    "                value = self.value_function.get(next_state, 0)\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_action = action\n",
    "            self.policy[state] = best_action\n",
    "\n",
    "    def get_next_state(self, game, action):\n",
    "        # Get the next state after making a move\n",
    "        game.make_move(action, 'X')  # Assuming X is the current player\n",
    "        return tuple(game.board)\n",
    "\n",
    "    def reward(self, game):\n",
    "        # Define the reward structure\n",
    "        if game.current_winner == 'X':\n",
    "            return 1\n",
    "        elif game.current_winner == 'O':\n",
    "            return -1\n",
    "        elif not game.empty_squares():\n",
    "            return 0  # Draw\n",
    "        return 0  # For non-terminal states\n",
    "\n",
    "    def play_game(self, game):\n",
    "        # Play a game using the current policy\n",
    "        game.reset()\n",
    "        while not game.is_terminal():\n",
    "            state = tuple(game.board)\n",
    "            action = self.choose_action(state, game.available_moves())\n",
    "            game.make_move(action, 'X')\n",
    "            game.make_move(random.choice(game.available_moves()), 'O')  # Opponent plays randomly\n",
    "            if game.current_winner:\n",
    "                break\n",
    "        if game.current_winner:\n",
    "            print(f\"{game.current_winner} wins!\")\n",
    "        else:\n",
    "            print(\"It's a tie!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96e97dcc-5b6c-4db8-a2b8-665b4f54b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     agent\u001b[38;5;241m.\u001b[39mplay_game(game)  \u001b[38;5;66;03m# Test the agent after training\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtrain_policy_iteration_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 11\u001b[0m, in \u001b[0;36mtrain_policy_iteration_agent\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     agent\u001b[38;5;241m.\u001b[39mimprove_policy(game)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 75\u001b[0m, in \u001b[0;36mPolicyIterationAgent.play_game\u001b[1;34m(self, game)\u001b[0m\n\u001b[0;32m     73\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoose_action(state, game\u001b[38;5;241m.\u001b[39mavailable_moves())\n\u001b[0;32m     74\u001b[0m game\u001b[38;5;241m.\u001b[39mmake_move(action, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m game\u001b[38;5;241m.\u001b[39mmake_move(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavailable_moves\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Opponent plays randomly\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m game\u001b[38;5;241m.\u001b[39mcurrent_winner:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\random.py:373\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "def train_policy_iteration_agent():\n",
    "    game = TicTacToe()\n",
    "    agent = PolicyIterationAgent()\n",
    "    agent.initialize(game)\n",
    "\n",
    "    for i in range(3000):  # Train over 1000 iterations\n",
    "        agent.evaluate_policy(game)\n",
    "        agent.improve_policy(game)\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    agent.play_game(game)  # Test the agent after training\n",
    "\n",
    "train_policy_iteration_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7f4b1-2403-445a-8770-b76a3cac9fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e82a18-4f35-458a-8d30-ae29b85d8474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
